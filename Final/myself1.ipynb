{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24839162",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-29T08:21:08.948197Z",
     "iopub.status.busy": "2024-11-29T08:21:08.947947Z",
     "iopub.status.idle": "2024-11-29T08:21:08.955030Z",
     "shell.execute_reply": "2024-11-29T08:21:08.954243Z"
    },
    "papermill": {
     "duration": 0.01418,
     "end_time": "2024-11-29T08:21:08.956570",
     "exception": false,
     "start_time": "2024-11-29T08:21:08.942390",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, math, numpy as np\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98fdecd1",
   "metadata": {
    "_kg_hide-input": false,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2024-11-29T08:21:08.965724Z",
     "iopub.status.busy": "2024-11-29T08:21:08.965215Z",
     "iopub.status.idle": "2024-11-29T08:25:08.578969Z",
     "shell.execute_reply": "2024-11-29T08:25:08.577924Z"
    },
    "papermill": {
     "duration": 239.62007,
     "end_time": "2024-11-29T08:25:08.580725",
     "exception": false,
     "start_time": "2024-11-29T08:21:08.960655",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torch 2.4.0\r\n",
      "Uninstalling torch-2.4.0:\r\n",
      "  Successfully uninstalled torch-2.4.0\r\n",
      "Looking in links: /kaggle/input/making-wheels-of-necessary-packages-for-vllm\r\n",
      "Processing /kaggle/input/making-wheels-of-necessary-packages-for-vllm/vllm-0.5.3.post1-cp38-abi3-manylinux1_x86_64.whl\r\n",
      "Processing /kaggle/input/making-wheels-of-necessary-packages-for-vllm/cmake-3.30.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (from vllm)\r\n",
      "Requirement already satisfied: ninja in /opt/conda/lib/python3.10/site-packages (from vllm) (1.11.1.1)\r\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from vllm) (5.9.3)\r\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from vllm) (0.2.0)\r\n",
      "Requirement already satisfied: numpy<2.0.0 in /opt/conda/lib/python3.10/site-packages (from vllm) (1.26.4)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from vllm) (2.32.3)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from vllm) (4.66.4)\r\n",
      "Requirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.10/site-packages (from vllm) (9.0.0)\r\n",
      "Requirement already satisfied: transformers>=4.42.4 in /opt/conda/lib/python3.10/site-packages (from vllm) (4.44.0)\r\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in /opt/conda/lib/python3.10/site-packages (from vllm) (0.19.1)\r\n",
      "Requirement already satisfied: fastapi in /opt/conda/lib/python3.10/site-packages (from vllm) (0.111.0)\r\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from vllm) (3.9.5)\r\n",
      "Processing /kaggle/input/making-wheels-of-necessary-packages-for-vllm/openai-1.51.2-py3-none-any.whl (from vllm)\r\n",
      "Requirement already satisfied: uvicorn[standard] in /opt/conda/lib/python3.10/site-packages (from vllm) (0.30.1)\r\n",
      "Requirement already satisfied: pydantic>=2.0 in /opt/conda/lib/python3.10/site-packages (from vllm) (2.8.2)\r\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (from vllm) (9.5.0)\r\n",
      "Requirement already satisfied: prometheus-client>=0.18.0 in /opt/conda/lib/python3.10/site-packages (from vllm) (0.20.0)\r\n",
      "Processing /kaggle/input/making-wheels-of-necessary-packages-for-vllm/prometheus_fastapi_instrumentator-7.0.0-py3-none-any.whl (from vllm)\r\n",
      "Processing /kaggle/input/making-wheels-of-necessary-packages-for-vllm/tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (from vllm)\r\n",
      "Processing /kaggle/input/making-wheels-of-necessary-packages-for-vllm/lm_format_enforcer-0.10.3-py3-none-any.whl (from vllm)\r\n",
      "Processing /kaggle/input/making-wheels-of-necessary-packages-for-vllm/outlines-0.0.46-py3-none-any.whl (from vllm)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from vllm) (4.12.2)\r\n",
      "Requirement already satisfied: filelock>=3.10.4 in /opt/conda/lib/python3.10/site-packages (from vllm) (3.15.1)\r\n",
      "Requirement already satisfied: pyzmq in /opt/conda/lib/python3.10/site-packages (from vllm) (26.0.3)\r\n",
      "Requirement already satisfied: ray>=2.9 in /opt/conda/lib/python3.10/site-packages (from vllm) (2.24.0)\r\n",
      "Requirement already satisfied: nvidia-ml-py in /opt/conda/lib/python3.10/site-packages (from vllm) (11.495.46)\r\n",
      "Processing /kaggle/input/making-wheels-of-necessary-packages-for-vllm/torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl (from vllm)\r\n",
      "Processing /kaggle/input/making-wheels-of-necessary-packages-for-vllm/torchvision-0.18.1-cp310-cp310-manylinux1_x86_64.whl (from vllm)\r\n",
      "Processing /kaggle/input/making-wheels-of-necessary-packages-for-vllm/xformers-0.0.27-cp310-cp310-manylinux2014_x86_64.whl (from vllm)\r\n",
      "Processing /kaggle/input/making-wheels-of-necessary-packages-for-vllm/vllm_flash_attn-2.5.9.post1-cp310-cp310-manylinux1_x86_64.whl (from vllm)\r\n",
      "Processing /kaggle/input/making-wheels-of-necessary-packages-for-vllm/interegular-0.3.3-py37-none-any.whl (from lm-format-enforcer==0.10.3->vllm)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from lm-format-enforcer==0.10.3->vllm) (21.3)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from lm-format-enforcer==0.10.3->vllm) (6.0.2)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.3.1->vllm) (1.13.2)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.3.1->vllm) (3.3)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.1->vllm) (3.1.4)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch==2.3.1->vllm) (2024.6.1)\r\n",
      "Processing /kaggle/input/making-wheels-of-necessary-packages-for-vllm/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (from torch==2.3.1->vllm)\r\n",
      "Processing /kaggle/input/making-wheels-of-necessary-packages-for-vllm/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (from torch==2.3.1->vllm)\r\n",
      "Processing /kaggle/input/making-wheels-of-necessary-packages-for-vllm/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (from torch==2.3.1->vllm)\r\n",
      "Processing /kaggle/input/making-wheels-of-necessary-packages-for-vllm/nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (from torch==2.3.1->vllm)\r\n",
      "Processing /kaggle/input/making-wheels-of-necessary-packages-for-vllm/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (from torch==2.3.1->vllm)\r\n",
      "Processing /kaggle/input/making-wheels-of-necessary-packages-for-vllm/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (from torch==2.3.1->vllm)\r\n",
      "Processing /kaggle/input/making-wheels-of-necessary-packages-for-vllm/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (from torch==2.3.1->vllm)\r\n",
      "Processing /kaggle/input/making-wheels-of-necessary-packages-for-vllm/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (from torch==2.3.1->vllm)\r\n",
      "Processing /kaggle/input/making-wheels-of-necessary-packages-for-vllm/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (from torch==2.3.1->vllm)\r\n",
      "Processing /kaggle/input/making-wheels-of-necessary-packages-for-vllm/nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (from torch==2.3.1->vllm)\r\n",
      "Processing /kaggle/input/making-wheels-of-necessary-packages-for-vllm/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (from torch==2.3.1->vllm)\r\n",
      "Processing /kaggle/input/making-wheels-of-necessary-packages-for-vllm/triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (from torch==2.3.1->vllm)\r\n",
      "Processing /kaggle/input/making-wheels-of-necessary-packages-for-vllm/nvidia_nvjitlink_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.1->vllm)\r\n",
      "Processing /kaggle/input/making-wheels-of-necessary-packages-for-vllm/lark-1.2.2-py3-none-any.whl (from outlines<0.1,>=0.0.43->vllm)\r\n",
      "Requirement already satisfied: nest-asyncio in /opt/conda/lib/python3.10/site-packages (from outlines<0.1,>=0.0.43->vllm) (1.6.0)\r\n",
      "Requirement already satisfied: cloudpickle in /opt/conda/lib/python3.10/site-packages (from outlines<0.1,>=0.0.43->vllm) (3.0.0)\r\n",
      "Processing /kaggle/input/making-wheels-of-necessary-packages-for-vllm/diskcache-5.6.3-py3-none-any.whl (from outlines<0.1,>=0.0.43->vllm)\r\n",
      "Requirement already satisfied: numba in /opt/conda/lib/python3.10/site-packages (from outlines<0.1,>=0.0.43->vllm) (0.58.1)\r\n",
      "Requirement already satisfied: referencing in /opt/conda/lib/python3.10/site-packages (from outlines<0.1,>=0.0.43->vllm) (0.35.1)\r\n",
      "Requirement already satisfied: jsonschema in /opt/conda/lib/python3.10/site-packages (from outlines<0.1,>=0.0.43->vllm) (4.22.0)\r\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from outlines<0.1,>=0.0.43->vllm) (2.21.0)\r\n",
      "Processing /kaggle/input/making-wheels-of-necessary-packages-for-vllm/pycountry-24.6.1-py3-none-any.whl (from outlines<0.1,>=0.0.43->vllm)\r\n",
      "Processing /kaggle/input/making-wheels-of-necessary-packages-for-vllm/pyairports-2.1.1-py3-none-any.whl (from outlines<0.1,>=0.0.43->vllm)\r\n",
      "Requirement already satisfied: starlette<1.0.0,>=0.30.0 in /opt/conda/lib/python3.10/site-packages (from prometheus-fastapi-instrumentator>=7.0.0->vllm) (0.37.2)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.0->vllm) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.0->vllm) (2.20.1)\r\n",
      "Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.10/site-packages (from ray>=2.9->vllm) (8.1.7)\r\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from ray>=2.9->vllm) (1.0.8)\r\n",
      "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /opt/conda/lib/python3.10/site-packages (from ray>=2.9->vllm) (3.20.3)\r\n",
      "Requirement already satisfied: aiosignal in /opt/conda/lib/python3.10/site-packages (from ray>=2.9->vllm) (1.3.1)\r\n",
      "Requirement already satisfied: frozenlist in /opt/conda/lib/python3.10/site-packages (from ray>=2.9->vllm) (1.4.1)\r\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.10/site-packages (from tiktoken>=0.6.0->vllm) (2024.5.15)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->vllm) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->vllm) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->vllm) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->vllm) (2024.7.4)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from tokenizers>=0.19.1->vllm) (0.24.6)\r\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.42.4->vllm) (0.4.4)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->vllm) (23.2.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->vllm) (6.0.5)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->vllm) (1.9.4)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->vllm) (4.0.3)\r\n",
      "Requirement already satisfied: fastapi-cli>=0.0.2 in /opt/conda/lib/python3.10/site-packages (from fastapi->vllm) (0.0.4)\r\n",
      "Requirement already satisfied: httpx>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from fastapi->vllm) (0.27.0)\r\n",
      "Requirement already satisfied: python-multipart>=0.0.7 in /opt/conda/lib/python3.10/site-packages (from fastapi->vllm) (0.0.9)\r\n",
      "Requirement already satisfied: ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from fastapi->vllm) (5.10.0)\r\n",
      "Requirement already satisfied: orjson>=3.2.1 in /opt/conda/lib/python3.10/site-packages (from fastapi->vllm) (3.10.4)\r\n",
      "Requirement already satisfied: email_validator>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from fastapi->vllm) (2.1.1)\r\n",
      "Requirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]->vllm) (0.14.0)\r\n",
      "Requirement already satisfied: httptools>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]->vllm) (0.6.1)\r\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]->vllm) (1.0.1)\r\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]->vllm) (0.19.0)\r\n",
      "Requirement already satisfied: watchfiles>=0.13 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]->vllm) (0.22.0)\r\n",
      "Requirement already satisfied: websockets>=10.4 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]->vllm) (12.0)\r\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from openai->vllm) (4.4.0)\r\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from openai->vllm) (1.9.0)\r\n",
      "Processing /kaggle/input/making-wheels-of-necessary-packages-for-vllm/jiter-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (from openai->vllm)\r\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from openai->vllm) (1.3.1)\r\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai->vllm) (1.2.0)\r\n",
      "Requirement already satisfied: dnspython>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from email_validator>=2.0.0->fastapi->vllm) (2.6.1)\r\n",
      "Requirement already satisfied: typer>=0.12.3 in /opt/conda/lib/python3.10/site-packages (from fastapi-cli>=0.0.2->fastapi->vllm) (0.12.3)\r\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx>=0.23.0->fastapi->vllm) (1.0.5)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch==2.3.1->vllm) (2.1.5)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->lm-format-enforcer==0.10.3->vllm) (3.1.2)\r\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->outlines<0.1,>=0.0.43->vllm) (16.1.0)\r\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets->outlines<0.1,>=0.0.43->vllm) (0.3.8)\r\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->outlines<0.1,>=0.0.43->vllm) (2.2.2)\r\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->outlines<0.1,>=0.0.43->vllm) (3.4.1)\r\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->outlines<0.1,>=0.0.43->vllm) (0.70.16)\r\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema->outlines<0.1,>=0.0.43->vllm) (2023.12.1)\r\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema->outlines<0.1,>=0.0.43->vllm) (0.18.1)\r\n",
      "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba->outlines<0.1,>=0.0.43->vllm) (0.41.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.3.1->vllm) (1.3.0)\r\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from typer>=0.12.3->fastapi-cli>=0.0.2->fastapi->vllm) (1.5.4)\r\n",
      "Requirement already satisfied: rich>=10.11.0 in /opt/conda/lib/python3.10/site-packages (from typer>=0.12.3->fastapi-cli>=0.0.2->fastapi->vllm) (13.7.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->outlines<0.1,>=0.0.43->vllm) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->outlines<0.1,>=0.0.43->vllm) (2024.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->outlines<0.1,>=0.0.43->vllm) (2024.1)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets->outlines<0.1,>=0.0.43->vllm) (1.16.0)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi->vllm) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi->vllm) (2.18.0)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi->vllm) (0.1.2)\r\n",
      "Installing collected packages: pyairports, triton, pycountry, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lark, jiter, interegular, diskcache, cmake, tiktoken, nvidia-cusparse-cu12, nvidia-cudnn-cu12, prometheus-fastapi-instrumentator, openai, nvidia-cusolver-cu12, lm-format-enforcer, torch, xformers, vllm-flash-attn, torchvision, outlines, vllm\r\n",
      "  Attempting uninstall: torchvision\r\n",
      "    Found existing installation: torchvision 0.19.0\r\n",
      "    Uninstalling torchvision-0.19.0:\r\n",
      "      Successfully uninstalled torchvision-0.19.0\r\n",
      "Successfully installed cmake-3.30.4 diskcache-5.6.3 interegular-0.3.3 jiter-0.6.1 lark-1.2.2 lm-format-enforcer-0.10.3 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.77 nvidia-nvtx-cu12-12.1.105 openai-1.51.2 outlines-0.0.46 prometheus-fastapi-instrumentator-7.0.0 pyairports-2.1.1 pycountry-24.6.1 tiktoken-0.8.0 torch-2.3.1 torchvision-0.18.1 triton-2.3.1 vllm-0.5.3.post1 vllm-flash-attn-2.5.9.post1 xformers-0.0.27\r\n",
      "Processing /kaggle/input/vllm-t4-fix/grpcio-1.62.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "grpcio is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\r\n",
      "Processing /kaggle/input/vllm-t4-fix/ray-2.11.0-cp310-cp310-manylinux2014_x86_64.whl\r\n",
      "Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.10/site-packages (from ray==2.11.0) (8.1.7)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from ray==2.11.0) (3.15.1)\r\n",
      "Requirement already satisfied: jsonschema in /opt/conda/lib/python3.10/site-packages (from ray==2.11.0) (4.22.0)\r\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from ray==2.11.0) (1.0.8)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from ray==2.11.0) (21.3)\r\n",
      "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /opt/conda/lib/python3.10/site-packages (from ray==2.11.0) (3.20.3)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from ray==2.11.0) (6.0.2)\r\n",
      "Requirement already satisfied: aiosignal in /opt/conda/lib/python3.10/site-packages (from ray==2.11.0) (1.3.1)\r\n",
      "Requirement already satisfied: frozenlist in /opt/conda/lib/python3.10/site-packages (from ray==2.11.0) (1.4.1)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from ray==2.11.0) (2.32.3)\r\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray==2.11.0) (23.2.0)\r\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray==2.11.0) (2023.12.1)\r\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray==2.11.0) (0.35.1)\r\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray==2.11.0) (0.18.1)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->ray==2.11.0) (3.1.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->ray==2.11.0) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->ray==2.11.0) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->ray==2.11.0) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->ray==2.11.0) (2024.7.4)\r\n",
      "Installing collected packages: ray\r\n",
      "  Attempting uninstall: ray\r\n",
      "    Found existing installation: ray 2.24.0\r\n",
      "    Uninstalling ray-2.24.0:\r\n",
      "      Successfully uninstalled ray-2.24.0\r\n",
      "Successfully installed ray-2.11.0\r\n",
      "Processing /kaggle/input/hf-libraries/sentence-transformers/sentence_transformers-3.1.0-py3-none-any.whl\r\n",
      "Installing collected packages: sentence-transformers\r\n",
      "Successfully installed sentence-transformers-3.1.0\r\n",
      "CPU times: user 2.44 s, sys: 589 ms, total: 3.03 s\n",
      "Wall time: 3min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!pip uninstall -y torch\n",
    "!pip install --no-index --find-links=/kaggle/input/making-wheels-of-necessary-packages-for-vllm vllm\n",
    "!pip install -U --upgrade /kaggle/input/vllm-t4-fix/grpcio-1.62.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
    "!pip install -U --upgrade /kaggle/input/vllm-t4-fix/ray-2.11.0-cp310-cp310-manylinux2014_x86_64.whl\n",
    "!pip install --no-deps --no-index /kaggle/input/hf-libraries/sentence-transformers/sentence_transformers-3.1.0-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0258fbd5",
   "metadata": {
    "papermill": {
     "duration": 0.007027,
     "end_time": "2024-11-29T08:25:08.595239",
     "exception": false,
     "start_time": "2024-11-29T08:25:08.588212",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4dbf378",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T08:25:08.610758Z",
     "iopub.status.busy": "2024-11-29T08:25:08.610481Z",
     "iopub.status.idle": "2024-11-29T08:25:08.617427Z",
     "shell.execute_reply": "2024-11-29T08:25:08.616384Z"
    },
    "papermill": {
     "duration": 0.016534,
     "end_time": "2024-11-29T08:25:08.619056",
     "exception": false,
     "start_time": "2024-11-29T08:25:08.602522",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing eedi_metrics.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile eedi_metrics.py\n",
    "\n",
    "# Credit: https://www.kaggle.com/code/abdullahmeda/eedi-map-k-metric\n",
    "\n",
    "import numpy as np\n",
    "def apk(actual, predicted, k=25):\n",
    "    \"\"\"\n",
    "    Computes the average precision at k.\n",
    "    \n",
    "    This function computes the average prescision at k between two lists of\n",
    "    items.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of elements that are to be predicted (order doesn't matter)\n",
    "    predicted : list\n",
    "                A list of predicted elements (order does matter)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The average precision at k over the input lists\n",
    "    \"\"\"\n",
    "    \n",
    "    if not actual:\n",
    "        return 0.0\n",
    "\n",
    "    if len(predicted)>k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i,p in enumerate(predicted):\n",
    "        # first condition checks whether it is valid prediction\n",
    "        # second condition checks if prediction is not repeated\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "def mapk(actual, predicted, k=25):\n",
    "    \"\"\"\n",
    "    Computes the mean average precision at k.\n",
    "    \n",
    "    This function computes the mean average prescision at k between two lists\n",
    "    of lists of items.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of lists of elements that are to be predicted \n",
    "             (order doesn't matter in the lists)\n",
    "    predicted : list\n",
    "                A list of lists of predicted elements\n",
    "                (order matters in the lists)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The mean average precision at k over the input lists\n",
    "    \"\"\"\n",
    "    \n",
    "    return np.mean([apk(a,p,k) for a,p in zip(actual, predicted)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b100d51",
   "metadata": {
    "papermill": {
     "duration": 0.006591,
     "end_time": "2024-11-29T08:25:08.632398",
     "exception": false,
     "start_time": "2024-11-29T08:25:08.625807",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Prepare dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e565a9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T08:25:08.647213Z",
     "iopub.status.busy": "2024-11-29T08:25:08.646988Z",
     "iopub.status.idle": "2024-11-29T08:25:14.357847Z",
     "shell.execute_reply": "2024-11-29T08:25:14.357170Z"
    },
    "papermill": {
     "duration": 5.720947,
     "end_time": "2024-11-29T08:25:14.360060",
     "exception": false,
     "start_time": "2024-11-29T08:25:08.639113",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IS SUBMISSION\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from transformers import AutoTokenizer\n",
    "import pandas as pd\n",
    "\n",
    "VALID_DATA_SIZE = 50\n",
    "IS_SUBMISSION = True #bool(os.getenv(\"KAGGLE_IS_COMPETITION_RERUN\"))\n",
    "if IS_SUBMISSION:\n",
    "    print(\"IS SUBMISSION\")\n",
    "else:\n",
    "    print(\"IS NOT SUBMISSION\")\n",
    "df_train = pd.read_csv(\"/kaggle/input/eedi-mining-misconceptions-in-mathematics/train.csv\").fillna(-1).iloc[:VALID_DATA_SIZE]\n",
    "df_test = pd.read_csv(\"/kaggle/input/eedi-mining-misconceptions-in-mathematics/test.csv\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/kaggle/input/hugging-quants-meta-llama-3-1-8b-instruct-awq-int4\")\n",
    "\n",
    "PROMPT  = \"\"\"Question: {Question}\n",
    "Incorrect Answer: {IncorrectAnswer}\n",
    "Correct Answer: {CorrectAnswer}\n",
    "Construct Name: {ConstructName}\n",
    "Subject Name: {SubjectName}\n",
    "\n",
    "Your task: Identify the misconception behind Incorrect Answer. Answer concisely and generically inside <response>$$INSERT TEXT HERE$$</response>.\n",
    "Before answering the question think step by step concisely in 1-2 sentence inside <thinking>$$INSERT TEXT HERE$$</thinking> tag and respond your final misconception inside <response>$$INSERT TEXT HERE$$</response> tag.\"\"\"\n",
    "\n",
    "def apply_template(row, tokenizer, targetCol):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": PROMPT.format(\n",
    "                 ConstructName=row[\"ConstructName\"],\n",
    "                 SubjectName=row[\"SubjectName\"],\n",
    "                 Question=row[\"QuestionText\"],\n",
    "                 IncorrectAnswer=row[f\"Answer{targetCol}Text\"],\n",
    "                 CorrectAnswer=row[f\"Answer{row.CorrectAnswer}Text\"])\n",
    "        }\n",
    "    ]\n",
    "    text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    return text\n",
    "\n",
    "df = {}\n",
    "if not IS_SUBMISSION:\n",
    "    df_label = {}\n",
    "    for idx, row in df_train.iterrows():\n",
    "        for option in [\"A\", \"B\", \"C\", \"D\"]:\n",
    "            if (row.CorrectAnswer!=option) & (row[f\"Misconception{option}Id\"]!=-1):\n",
    "                df[f\"{row.QuestionId}_{option}\"] = apply_template(row, tokenizer, option)\n",
    "                df_label[f\"{row.QuestionId}_{option}\"] = [row[f\"Misconception{option}Id\"]]\n",
    "    df_label = pd.DataFrame([df_label]).T.reset_index()\n",
    "    df_label.columns = [\"QuestionId_Answer\", \"MisconceptionId\"]\n",
    "    df_label.to_parquet(\"label.parquet\", index=False)\n",
    "else:\n",
    "    for idx, row in df_test.iterrows():\n",
    "        for option in [\"A\", \"B\", \"C\", \"D\"]:\n",
    "            if row.CorrectAnswer!=option:\n",
    "                df[f\"{row.QuestionId}_{option}\"] = apply_template(row, tokenizer, option)\n",
    "df = pd.DataFrame([df]).T.reset_index()\n",
    "df.columns = [\"QuestionId_Answer\", \"text\"]\n",
    "df.to_parquet(\"submission.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5be6b1c",
   "metadata": {
    "papermill": {
     "duration": 0.007482,
     "end_time": "2024-11-29T08:25:14.374851",
     "exception": false,
     "start_time": "2024-11-29T08:25:14.367369",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## LLM Reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fae115c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T08:25:14.390198Z",
     "iopub.status.busy": "2024-11-29T08:25:14.389843Z",
     "iopub.status.idle": "2024-11-29T08:25:14.395548Z",
     "shell.execute_reply": "2024-11-29T08:25:14.394744Z"
    },
    "papermill": {
     "duration": 0.015243,
     "end_time": "2024-11-29T08:25:14.397225",
     "exception": false,
     "start_time": "2024-11-29T08:25:14.381982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing run_vllm.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile run_vllm.py\n",
    "\n",
    "import re\n",
    "import vllm\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet(\"submission.parquet\")\n",
    "\n",
    "llm = vllm.LLM(\n",
    "    \"/kaggle/input/hugging-quants-meta-llama-3-1-8b-instruct-awq-int4\",\n",
    "    quantization=\"awq\",\n",
    "    tensor_parallel_size=2, \n",
    "    gpu_memory_utilization=0.95, \n",
    "    trust_remote_code=True,\n",
    "    dtype=\"half\", \n",
    "    enforce_eager=True,\n",
    "    max_model_len=8192,\n",
    "    disable_log_stats=True\n",
    ")\n",
    "tokenizer = llm.get_tokenizer()\n",
    "\n",
    "\n",
    "responses = llm.generate(\n",
    "    df[\"text\"].values,\n",
    "    vllm.SamplingParams(\n",
    "        n=1,  # Number of output sequences to return for each prompt.\n",
    "        top_p=0.9,  # Float that controls the cumulative probability of the top tokens to consider.\n",
    "        temperature=0,  # randomness of the sampling\n",
    "        seed=777, # Seed for reprodicibility\n",
    "        skip_special_tokens=False,  # Whether to skip special tokens in the output.\n",
    "        max_tokens=2048,  # Maximum number of tokens to generate per output sequence.\n",
    "    ),\n",
    "    use_tqdm = True\n",
    ")\n",
    "\n",
    "responses = [x.outputs[0].text for x in responses]\n",
    "df[\"fullLLMText\"] = responses\n",
    "\n",
    "def extract_response(text):\n",
    "    return \",\".join(re.findall(r\"<response>(.*?)</response>\", text)).strip()\n",
    "\n",
    "responses = [extract_response(x) for x in responses]\n",
    "df[\"llmMisconception\"] = responses\n",
    "df.to_parquet(\"submission.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d669518c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T08:25:14.412335Z",
     "iopub.status.busy": "2024-11-29T08:25:14.412107Z",
     "iopub.status.idle": "2024-11-29T08:26:34.808904Z",
     "shell.execute_reply": "2024-11-29T08:26:34.807722Z"
    },
    "papermill": {
     "duration": 80.406499,
     "end_time": "2024-11-29T08:26:34.811034",
     "exception": false,
     "start_time": "2024-11-29T08:25:14.404535",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 11-29 08:25:19 config.py:246] awq quantization is not fully optimized yet. The speed can be slower than non-quantized models.\r\n",
      "INFO 11-29 08:25:19 config.py:715] Defaulting to use mp for distributed inference\r\n",
      "INFO 11-29 08:25:19 llm_engine.py:176] Initializing an LLM engine (v0.5.3.post1) with config: model='/kaggle/input/hugging-quants-meta-llama-3-1-8b-instruct-awq-int4', speculative_config=None, tokenizer='/kaggle/input/hugging-quants-meta-llama-3-1-8b-instruct-awq-int4', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=2, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=awq, enforce_eager=True, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None), seed=0, served_model_name=/kaggle/input/hugging-quants-meta-llama-3-1-8b-instruct-awq-int4, use_v2_block_manager=False, enable_prefix_caching=False)\r\n",
      "INFO 11-29 08:25:19 custom_cache_manager.py:17] Setting Triton cache manager to: vllm.triton_utils.custom_cache_manager:CustomCacheManager\r\n",
      "INFO 11-29 08:25:19 selector.py:151] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\r\n",
      "\u001b[1;36m(VllmWorkerProcess pid=89)\u001b[0;0m INFO 11-29 08:25:19 selector.py:151] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\r\n",
      "INFO 11-29 08:25:19 selector.py:54] Using XFormers backend.\r\n",
      "\u001b[1;36m(VllmWorkerProcess pid=89)\u001b[0;0m INFO 11-29 08:25:19 selector.py:54] Using XFormers backend.\r\n",
      "\u001b[1;36m(VllmWorkerProcess pid=89)\u001b[0;0m INFO 11-29 08:25:22 multiproc_worker_utils.py:215] Worker ready; awaiting tasks\r\n",
      "\u001b[1;36m(VllmWorkerProcess pid=89)\u001b[0;0m INFO 11-29 08:25:23 utils.py:784] Found nccl from library libnccl.so.2\r\n",
      "INFO 11-29 08:25:23 utils.py:784] Found nccl from library libnccl.so.2\r\n",
      "INFO 11-29 08:25:23 pynccl.py:63] vLLM is using nccl==2.20.5\r\n",
      "\u001b[1;36m(VllmWorkerProcess pid=89)\u001b[0;0m INFO 11-29 08:25:23 pynccl.py:63] vLLM is using nccl==2.20.5\r\n",
      "INFO 11-29 08:25:23 custom_all_reduce_utils.py:202] generating GPU P2P access cache in /root/.cache/vllm/gpu_p2p_access_cache_for_0,1.json\r\n",
      "INFO 11-29 08:25:30 custom_all_reduce_utils.py:232] reading GPU P2P access cache from /root/.cache/vllm/gpu_p2p_access_cache_for_0,1.json\r\n",
      "\u001b[1;36m(VllmWorkerProcess pid=89)\u001b[0;0m INFO 11-29 08:25:30 custom_all_reduce_utils.py:232] reading GPU P2P access cache from /root/.cache/vllm/gpu_p2p_access_cache_for_0,1.json\r\n",
      "\u001b[1;36m(VllmWorkerProcess pid=89)\u001b[0;0m WARNING 11-29 08:25:30 custom_all_reduce.py:127] Custom allreduce is disabled because your platform lacks GPU P2P capability or P2P test failed. To silence this warning, specify disable_custom_all_reduce=True explicitly.\r\n",
      "WARNING 11-29 08:25:30 custom_all_reduce.py:127] Custom allreduce is disabled because your platform lacks GPU P2P capability or P2P test failed. To silence this warning, specify disable_custom_all_reduce=True explicitly.\r\n",
      "INFO 11-29 08:25:30 shm_broadcast.py:241] vLLM message queue communication handle: Handle(connect_ip='127.0.0.1', local_reader_ranks=[1], buffer=<vllm.distributed.device_communicators.shm_broadcast.ShmRingBuffer object at 0x7fd854d4a560>, local_subscribe_port=47489, local_sync_port=51895, remote_subscribe_port=None, remote_sync_port=None)\r\n",
      "INFO 11-29 08:25:30 model_runner.py:680] Starting to load model /kaggle/input/hugging-quants-meta-llama-3-1-8b-instruct-awq-int4...\r\n",
      "\u001b[1;36m(VllmWorkerProcess pid=89)\u001b[0;0m INFO 11-29 08:25:30 model_runner.py:680] Starting to load model /kaggle/input/hugging-quants-meta-llama-3-1-8b-instruct-awq-int4...\r\n",
      "\u001b[1;36m(VllmWorkerProcess pid=89)\u001b[0;0m INFO 11-29 08:25:30 selector.py:151] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\r\n",
      "INFO 11-29 08:25:30 selector.py:151] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\r\n",
      "\u001b[1;36m(VllmWorkerProcess pid=89)\u001b[0;0m INFO 11-29 08:25:30 selector.py:54] Using XFormers backend.\r\n",
      "INFO 11-29 08:25:30 selector.py:54] Using XFormers backend.\r\n",
      "Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]\r\n",
      "Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:34<00:34, 34.39s/it]\r\n",
      "Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:39<00:00, 17.25s/it]\r\n",
      "Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:39<00:00, 19.82s/it]\r\n",
      "\r\n",
      "INFO 11-29 08:26:10 model_runner.py:692] Loading model weights took 2.7007 GB\r\n",
      "\u001b[1;36m(VllmWorkerProcess pid=89)\u001b[0;0m INFO 11-29 08:26:10 model_runner.py:692] Loading model weights took 2.7007 GB\r\n",
      "INFO 11-29 08:26:14 distributed_gpu_executor.py:56] # GPU blocks: 9196, # CPU blocks: 4096\r\n",
      "Processed prompts: 100%|█| 9/9 [00:12<00:00,  1.33s/it, est. speed input: 163.53\r\n",
      "INFO 11-29 08:26:31 multiproc_worker_utils.py:123] Killing local vLLM worker processes\r\n",
      "Fatal Python error: _enter_buffered_busy: could not acquire lock for <_io.BufferedWriter name='<stdout>'> at interpreter shutdown, possibly due to daemon threads\r\n",
      "Python runtime state: finalizing (tstate=0x00005baad32a1880)\r\n",
      "\r\n",
      "Current thread 0x00007fd9683e5740 (most recent call first):\r\n",
      "  <no Python frame>\r\n",
      "\r\n",
      "Extension modules: numpy.core._multiarray_umath, numpy.core._multiarray_tests, numpy.linalg._umath_linalg, numpy.fft._pocketfft_internal, numpy.random._common, numpy.random.bit_generator, numpy.random._bounded_integers, numpy.random._mt19937, numpy.random.mtrand, numpy.random._philox, numpy.random._pcg64, numpy.random._sfc64, numpy.random._generator, torch._C, torch._C._fft, torch._C._linalg, torch._C._nested, torch._C._nn, torch._C._sparse, torch._C._special, _cffi_backend, zstandard.backend_c, simplejson._speedups, yaml._yaml, psutil._psutil_linux, psutil._psutil_posix, sentencepiece._sentencepiece, msgpack._cmsgpack, google.protobuf.pyext._message, google3.net.proto2.python.internal.cpp._message, setproctitle, uvloop.loop, ray._raylet, multidict._multidict, yarl._quoting_c, aiohttp._helpers, aiohttp._http_writer, aiohttp._http_parser, aiohttp._websocket, frozenlist._frozenlist, pyarrow.lib, pandas._libs.tslibs.ccalendar, pandas._libs.tslibs.np_datetime, pandas._libs.tslibs.dtypes, pandas._libs.tslibs.base, pandas._libs.tslibs.nattype, pandas._libs.tslibs.timezones, pandas._libs.tslibs.fields, pandas._libs.tslibs.timedeltas, pandas._libs.tslibs.tzconversion, pandas._libs.tslibs.timestamps, pandas._libs.properties, pandas._libs.tslibs.offsets, pandas._libs.tslibs.strptime, pandas._libs.tslibs.parsing, pandas._libs.tslibs.conversion, pandas._libs.tslibs.period, pandas._libs.tslibs.vectorized, pandas._libs.ops_dispatch, pandas._libs.missing, pandas._libs.hashtable, pandas._libs.algos, pandas._libs.interval, pandas._libs.lib, pyarrow._compute, pandas._libs.ops, numexpr.interpreter, pandas._libs.hashing, pandas._libs.arrays, pandas._libs.tslib, pandas._libs.sparse, pandas._libs.internals, pandas._libs.indexing, pandas._libs.index, pandas._libs.writers, pandas._libs.join, pandas._libs.window.aggregations, pandas._libs.window.indexers, pandas._libs.reshape, pandas._libs.groupby, pandas._libs.json, pandas._libs.parsers, pandas._libs.testing, pyarrow._parquet, pyarrow._fs, pyarrow._azurefs, pyarrow._hdfs, pyarrow._gcsfs, pyarrow._s3fs, pyarrow._acero, pyarrow._csv, pyarrow._json, pyarrow._dataset, pyarrow._dataset_orc, pyarrow._parquet_encryption, pyarrow._dataset_parquet_encryption, pyarrow._dataset_parquet, lz4._version, lz4.frame._frame, PIL._imaging, cython.cimports.libc.math, scipy._lib._ccallback_c, scipy.linalg._fblas, scipy.linalg._flapack, scipy.linalg.cython_lapack, scipy.linalg._cythonized_array_utils, scipy.linalg._solve_toeplitz, scipy.linalg._decomp_lu_cython, scipy.linalg._matfuncs_sqrtm_triu, scipy.linalg.cython_blas, scipy.linalg._matfuncs_expm, scipy.linalg._decomp_update, scipy.sparse._sparsetools, _csparsetools, scipy.sparse._csparsetools, scipy.sparse.linalg._dsolve._superlu, scipy.sparse.linalg._eigen.arpack._arpack, scipy.sparse.linalg._propack._spropack, scipy.sparse.linalg._propack._dpropack, scipy.sparse.linalg._propack._cpropack, scipy.sparse.linalg._propack._zpropack, scipy.sparse.csgraph._tools, scipy.sparse.csgraph._shortest_path, scipy.sparse.csgraph._traversal, scipy.sparse.csgraph._min_spanning_tree, scipy.sparse.csgraph._flow, scipy.sparse.csgraph._matching, scipy.sparse.csgraph._reordering, scipy.optimize._group_columns, scipy._lib.messagestream, scipy.optimize._trlib._trlib, scipy.optimize._lbfgsb, _moduleTNC, scipy.optimize._moduleTNC, scipy.optimize._cobyla, scipy.optimize._slsqp, scipy.optimize._minpack, scipy.optimize._lsq.givens_elimination, scipy.optimize._zeros, scipy.optimize._highs.cython.src._highs_wrapper, scipy.optimize._highs._highs_wrapper, scipy.optimize._highs.cython.src._highs_constants, scipy.optimize._highs._highs_constants, scipy.linalg._interpolative, scipy.optimize._bglu_dense, scipy.optimize._lsap, scipy.spatial._ckdtree, scipy.spatial._qhull, scipy.spatial._voronoi, scipy.spatial._distance_wrap, scipy.spatial._hausdorff, scipy.special._ufuncs_cxx, scipy.special._ufuncs, scipy.special._specfun, scipy.special._comb, scipy.special._ellip_harm_2, scipy.spatial.transform._rotation, scipy.optimize._direct, zmq.backend.cython._zmq (total: 159)\r\n"
     ]
    }
   ],
   "source": [
    "!python run_vllm.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebac3789",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T08:26:34.830131Z",
     "iopub.status.busy": "2024-11-29T08:26:34.829798Z",
     "iopub.status.idle": "2024-11-29T08:26:34.863669Z",
     "shell.execute_reply": "2024-11-29T08:26:34.862253Z"
    },
    "papermill": {
     "duration": 0.045779,
     "end_time": "2024-11-29T08:26:34.865505",
     "exception": false,
     "start_time": "2024-11-29T08:26:34.819726",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<thinking> The incorrect answer suggests that the numerator can be factored into (m+3) and (m-1), which is not the case. This would imply that the numerator can be written as (m+3)(m-1) = m^2 + 2m - 3, which is incorrect as it does not equal the original numerator.</thinking>\n",
      "\n",
      "<response> The misconception behind the incorrect answer is that the numerator can be factored into (m+3) and (m-1), which is not true.</response>\n",
      "---------\n",
      "The misconception behind the incorrect answer is that the numerator can be factored into (m+3) and (m-1), which is not true.\n",
      "==================\n",
      "<thinking> The incorrect answer suggests that the numerator can be factored into a binomial that can be canceled out with the denominator, but this is not the case. The numerator does not factor into a binomial that matches the denominator.</thinking>\n",
      "\n",
      "<response> The misconception behind the incorrect answer is that the numerator can be factored into a binomial that can be canceled out with the denominator, when in fact it cannot.</response>\n",
      "---------\n",
      "The misconception behind the incorrect answer is that the numerator can be factored into a binomial that can be canceled out with the denominator, when in fact it cannot.\n",
      "==================\n",
      "<thinking>Range is the difference between the highest and lowest values in a dataset. If the values are changed (either by cutting in half or growing), the range will change because the difference between the highest and lowest values will change.</thinking>\n",
      "\n",
      "<response>Only Katie is correct. The range would change if all the plants were cut in half, but it would not change if all the plants grew by 3 cm each.</response>\n",
      "---------\n",
      "Only Katie is correct. The range would change if all the plants were cut in half, but it would not change if all the plants grew by 3 cm each.\n",
      "==================\n",
      "<thinking>First, let's calculate the range of the given plant heights: the difference between the largest and smallest values, which is \\( 42 - 13 = 29 \\mathrm{~cm} \\). If all plants were cut in half, the new heights would be \\( 12 \\mathrm{~cm}, 8.5 \\mathrm{~cm}, 21 \\mathrm{~cm}, 13 \\mathrm{~cm}, 6.5 \\mathrm{~cm} \\), and the range would be \\( 21 - 6.5 = 14.5 \\mathrm{~cm} \\), which is less than the original range. If all plants grew by \\( 3 \\mathrm{~cm} \\), the new heights would be \\( 27 \\mathrm{~cm}, 20 \\mathrm{~cm}, 45 \\mathrm{~cm}, 29 \\mathrm{~cm}, 16 \\mathrm{~cm} \\), and the range would be \\( 45 - 16 = 29 \\mathrm{~cm} \\), which is the same as the original range.</thinking>\n",
      "\n",
      "<response>$$The misconception behind the incorrect answer \"Both Tom and Katie\" is that it assumes that both scenarios would result in the same range, which is not true. The correct answer is \"Only Katie\" because if all plants grew by \\( 3 \\mathrm{~cm} \\), the range would remain the same, but if all plants were cut in half, the range would decrease.</response>\n",
      "---------\n",
      "$$The misconception behind the incorrect answer \"Both Tom and Katie\" is that it assumes that both scenarios would result in the same range, which is not true. The correct answer is \"Only Katie\" because if all plants grew by \\( 3 \\mathrm{~cm} \\), the range would remain the same, but if all plants were cut in half, the range would decrease.\n",
      "==================\n",
      "<thinking>Range is the difference between the highest and lowest values in a dataset. If the values are changed (either by cutting in half or growing), the range will change because the difference between the highest and lowest values will change.</thinking>\n",
      "\n",
      "<response>Neither is correct</response>\n",
      "---------\n",
      "Neither is correct\n",
      "==================\n"
     ]
    }
   ],
   "source": [
    "llm_output = pd.read_parquet(\"submission.parquet\")\n",
    "\n",
    "for idx, row in llm_output[-5:].iterrows():\n",
    "    print(row.fullLLMText)\n",
    "    print(\"---\"*3)\n",
    "    print(row.llmMisconception)\n",
    "    print(\"===\"*6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7cd09c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T08:26:34.883788Z",
     "iopub.status.busy": "2024-11-29T08:26:34.883149Z",
     "iopub.status.idle": "2024-11-29T08:26:34.900279Z",
     "shell.execute_reply": "2024-11-29T08:26:34.899390Z"
    },
    "papermill": {
     "duration": 0.027934,
     "end_time": "2024-11-29T08:26:34.902015",
     "exception": false,
     "start_time": "2024-11-29T08:26:34.874081",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QuestionId_Answer</th>\n",
       "      <th>text</th>\n",
       "      <th>fullLLMText</th>\n",
       "      <th>llmMisconception</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1869_B</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>&lt;thinking&gt;When evaluating the expression \\( 3 ...</td>\n",
       "      <td>The misconception behind the incorrect answer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1869_C</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>&lt;thinking&gt;When evaluating the expression \\( 3 ...</td>\n",
       "      <td>The misconception behind the incorrect answer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1869_D</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>&lt;thinking&gt;Following the order of operations, t...</td>\n",
       "      <td>The misconception behind the incorrect answer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1870_A</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>&lt;thinking&gt; The incorrect answer suggests that ...</td>\n",
       "      <td>The misconception behind the incorrect answer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1870_B</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>&lt;thinking&gt; The incorrect answer suggests that ...</td>\n",
       "      <td>The misconception behind the incorrect answer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1870_C</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>&lt;thinking&gt; The incorrect answer suggests that ...</td>\n",
       "      <td>The misconception behind the incorrect answer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1871_A</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>&lt;thinking&gt;Range is the difference between the ...</td>\n",
       "      <td>Only Katie is correct. The range would change ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1871_C</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>&lt;thinking&gt;First, let's calculate the range of ...</td>\n",
       "      <td>$$The misconception behind the incorrect answe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1871_D</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>&lt;thinking&gt;Range is the difference between the ...</td>\n",
       "      <td>Neither is correct</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  QuestionId_Answer                                               text  \\\n",
       "0            1869_B  <|begin_of_text|><|start_header_id|>system<|en...   \n",
       "1            1869_C  <|begin_of_text|><|start_header_id|>system<|en...   \n",
       "2            1869_D  <|begin_of_text|><|start_header_id|>system<|en...   \n",
       "3            1870_A  <|begin_of_text|><|start_header_id|>system<|en...   \n",
       "4            1870_B  <|begin_of_text|><|start_header_id|>system<|en...   \n",
       "5            1870_C  <|begin_of_text|><|start_header_id|>system<|en...   \n",
       "6            1871_A  <|begin_of_text|><|start_header_id|>system<|en...   \n",
       "7            1871_C  <|begin_of_text|><|start_header_id|>system<|en...   \n",
       "8            1871_D  <|begin_of_text|><|start_header_id|>system<|en...   \n",
       "\n",
       "                                         fullLLMText  \\\n",
       "0  <thinking>When evaluating the expression \\( 3 ...   \n",
       "1  <thinking>When evaluating the expression \\( 3 ...   \n",
       "2  <thinking>Following the order of operations, t...   \n",
       "3  <thinking> The incorrect answer suggests that ...   \n",
       "4  <thinking> The incorrect answer suggests that ...   \n",
       "5  <thinking> The incorrect answer suggests that ...   \n",
       "6  <thinking>Range is the difference between the ...   \n",
       "7  <thinking>First, let's calculate the range of ...   \n",
       "8  <thinking>Range is the difference between the ...   \n",
       "\n",
       "                                    llmMisconception  \n",
       "0  The misconception behind the incorrect answer ...  \n",
       "1  The misconception behind the incorrect answer ...  \n",
       "2  The misconception behind the incorrect answer ...  \n",
       "3  The misconception behind the incorrect answer ...  \n",
       "4  The misconception behind the incorrect answer ...  \n",
       "5  The misconception behind the incorrect answer ...  \n",
       "6  Only Katie is correct. The range would change ...  \n",
       "7  $$The misconception behind the incorrect answe...  \n",
       "8                                 Neither is correct  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32f7eeb",
   "metadata": {
    "papermill": {
     "duration": 0.008235,
     "end_time": "2024-11-29T08:26:34.918828",
     "exception": false,
     "start_time": "2024-11-29T08:26:34.910593",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Find similar Misconception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e4fe766",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T08:26:34.936645Z",
     "iopub.status.busy": "2024-11-29T08:26:34.936419Z",
     "iopub.status.idle": "2024-11-29T08:26:35.071953Z",
     "shell.execute_reply": "2024-11-29T08:26:35.071287Z"
    },
    "papermill": {
     "duration": 0.146468,
     "end_time": "2024-11-29T08:26:35.073752",
     "exception": false,
     "start_time": "2024-11-29T08:26:34.927284",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_misconception_mapping = pd.read_csv(\"/kaggle/input/eedi-mining-misconceptions-in-mathematics/misconception_mapping.csv\")\n",
    "\n",
    "misconception_mapping_dict = {}\n",
    "for idx, row in df_misconception_mapping.iterrows():\n",
    "    misconception_mapping_dict[row['MisconceptionId']] = row['MisconceptionName']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7724194b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T08:26:35.094986Z",
     "iopub.status.busy": "2024-11-29T08:26:35.094332Z",
     "iopub.status.idle": "2024-11-29T08:26:35.304515Z",
     "shell.execute_reply": "2024-11-29T08:26:35.303607Z"
    },
    "papermill": {
     "duration": 0.222117,
     "end_time": "2024-11-29T08:26:35.306330",
     "exception": false,
     "start_time": "2024-11-29T08:26:35.084213",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "if IS_SUBMISSION:\n",
    "    train_df = pd.read_csv(\"/kaggle/input/eedi-mining-misconceptions-in-mathematics/train.csv\").fillna(-1)\n",
    "else:\n",
    "    train_df = pd.read_csv(\"/kaggle/input/eedi-mining-misconceptions-in-mathematics/train.csv\").fillna(-1).iloc[VALID_DATA_SIZE:]\n",
    "    \n",
    "misconception_mapping_to_example = defaultdict(list)\n",
    "for idx, row in train_df.iterrows():\n",
    "    for option in [\"A\", \"B\", \"C\", \"D\"]:\n",
    "        if (row.CorrectAnswer!=option) & (row[f\"Misconception{option}Id\"]!=-1):\n",
    "            misconception_mapping_to_example[row[f\"Misconception{option}Id\"]].append(\n",
    "                {\n",
    "                    \"ConstructName\": row['ConstructName'],\n",
    "                    \"SubjectName\" : row['SubjectName'],\n",
    "                    \"AnswerText\" : row[f\"Answer{option}Text\"],\n",
    "                    \"Misconception\": misconception_mapping_dict[row[f\"Misconception{option}Id\"]]\n",
    "                }\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d823c45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T08:26:35.325834Z",
     "iopub.status.busy": "2024-11-29T08:26:35.325548Z",
     "iopub.status.idle": "2024-11-29T08:26:35.330931Z",
     "shell.execute_reply": "2024-11-29T08:26:35.330167Z"
    },
    "papermill": {
     "duration": 0.016754,
     "end_time": "2024-11-29T08:26:35.332462",
     "exception": false,
     "start_time": "2024-11-29T08:26:35.315708",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ConstructName': 'Describe a descending linear sequence in words',\n",
       "  'SubjectName': 'Sequences-Others',\n",
       "  'AnswerText': 'The first term is \\\\( 7 \\\\) and the term-to-term rule is \\\\( +5 \\\\)',\n",
       "  'Misconception': 'Goes the wrong direction in the sequence when identifying term-to-term rule'},\n",
       " {'ConstructName': 'Find the nth term rule for a descending integer linear sequence',\n",
       "  'SubjectName': 'Linear Sequences (nth term)',\n",
       "  'AnswerText': '\\\\( 6 \\\\)',\n",
       "  'Misconception': 'Goes the wrong direction in the sequence when identifying term-to-term rule'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misconception_mapping_to_example[1716]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "312d06e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T08:26:35.351000Z",
     "iopub.status.busy": "2024-11-29T08:26:35.350723Z",
     "iopub.status.idle": "2024-11-29T08:26:35.357646Z",
     "shell.execute_reply": "2024-11-29T08:26:35.356873Z"
    },
    "papermill": {
     "duration": 0.018163,
     "end_time": "2024-11-29T08:26:35.359333",
     "exception": false,
     "start_time": "2024-11-29T08:26:35.341170",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MisconceptionId</th>\n",
       "      <th>MisconceptionName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Does not know that angles in a triangle sum to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Uses dividing fractions method for multiplying...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Believes there are 100 degrees in a full turn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Thinks a quadratic without a non variable term...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Believes addition of terms and powers of terms...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MisconceptionId                                  MisconceptionName\n",
       "0                0  Does not know that angles in a triangle sum to...\n",
       "1                1  Uses dividing fractions method for multiplying...\n",
       "2                2      Believes there are 100 degrees in a full turn\n",
       "3                3  Thinks a quadratic without a non variable term...\n",
       "4                4  Believes addition of terms and powers of terms..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_misconception_mapping.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e28b363",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T08:26:35.377564Z",
     "iopub.status.busy": "2024-11-29T08:26:35.377331Z",
     "iopub.status.idle": "2024-11-29T08:26:35.462422Z",
     "shell.execute_reply": "2024-11-29T08:26:35.461636Z"
    },
    "papermill": {
     "duration": 0.096138,
     "end_time": "2024-11-29T08:26:35.464108",
     "exception": false,
     "start_time": "2024-11-29T08:26:35.367970",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MisconceptionId</th>\n",
       "      <th>MisconceptionName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Does not know that angles in a triangle sum to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Uses dividing fractions method for multiplying...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Believes there are 100 degrees in a full turn\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Thinks a quadratic without a non variable term...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Believes addition of terms and powers of terms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2582</th>\n",
       "      <td>2582</td>\n",
       "      <td>When multiplying numbers with the same base, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2583</th>\n",
       "      <td>2583</td>\n",
       "      <td>Does not know what a cube number is\\n[{'Constr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2584</th>\n",
       "      <td>2584</td>\n",
       "      <td>Believes that any percentage of a larger numbe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2585</th>\n",
       "      <td>2585</td>\n",
       "      <td>Believes a cubic expression should have three ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2586</th>\n",
       "      <td>2586</td>\n",
       "      <td>Misunderstands order of operations in algebrai...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2587 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MisconceptionId                                  MisconceptionName\n",
       "0                   0  Does not know that angles in a triangle sum to...\n",
       "1                   1  Uses dividing fractions method for multiplying...\n",
       "2                   2  Believes there are 100 degrees in a full turn\\...\n",
       "3                   3  Thinks a quadratic without a non variable term...\n",
       "4                   4  Believes addition of terms and powers of terms...\n",
       "...               ...                                                ...\n",
       "2582             2582  When multiplying numbers with the same base, m...\n",
       "2583             2583  Does not know what a cube number is\\n[{'Constr...\n",
       "2584             2584  Believes that any percentage of a larger numbe...\n",
       "2585             2585  Believes a cubic expression should have three ...\n",
       "2586             2586  Misunderstands order of operations in algebrai...\n",
       "\n",
       "[2587 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# enhence misconception\n",
    "enhenced_df_misconception_mapping = df_misconception_mapping.copy()\n",
    "enhenced_df_misconception_mapping['MisconceptionName'] = df_misconception_mapping.apply( lambda x: x['MisconceptionName'] + \"\\n\" + str(misconception_mapping_to_example[x['MisconceptionId']])  , axis=1)\n",
    "enhenced_df_misconception_mapping.to_csv('enhenced_df_misconception_mapping.csv')\n",
    "enhenced_df_misconception_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4aa24815",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T08:26:35.483255Z",
     "iopub.status.busy": "2024-11-29T08:26:35.483029Z",
     "iopub.status.idle": "2024-11-29T08:26:35.488290Z",
     "shell.execute_reply": "2024-11-29T08:26:35.487424Z"
    },
    "papermill": {
     "duration": 0.016408,
     "end_time": "2024-11-29T08:26:35.489764",
     "exception": false,
     "start_time": "2024-11-29T08:26:35.473356",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing run_similarity_search.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile run_similarity_search.py\n",
    "\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "df = pd.read_parquet(\"submission.parquet\")\n",
    "enhenced_df_misconception_mapping = pd.read_csv(\"enhenced_df_misconception_mapping.csv\")\n",
    "\n",
    "model = SentenceTransformer('/kaggle/input/bge-large-en-v1-5')\n",
    "PREFIX = \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\n\"\n",
    "input_features = df[\"text\"].str.lstrip(PREFIX).str.split(\"\\n\\nYour task:\").str[0]\n",
    "\n",
    "embedding_query = model.encode(input_features+ \"\\n----\\n\" + df[\"fullLLMText\"], convert_to_tensor=True)\n",
    "embedding_Misconception = model.encode(enhenced_df_misconception_mapping.MisconceptionName.values, convert_to_tensor=True)\n",
    "\n",
    "top25ids = util.semantic_search(embedding_query, embedding_Misconception, top_k=25)\n",
    "\n",
    "df[\"MisconceptionId\"] = [\" \".join([str(x[\"corpus_id\"]) for x in top25id]) for top25id in top25ids]\n",
    "\n",
    "df[[\"QuestionId_Answer\", \"MisconceptionId\"]].to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39b3bc37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T08:26:35.509096Z",
     "iopub.status.busy": "2024-11-29T08:26:35.508396Z",
     "iopub.status.idle": "2024-11-29T08:28:27.695859Z",
     "shell.execute_reply": "2024-11-29T08:28:27.694661Z"
    },
    "papermill": {
     "duration": 112.199508,
     "end_time": "2024-11-29T08:28:27.698091",
     "exception": false,
     "start_time": "2024-11-29T08:26:35.498583",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batches: 100%|████████████████████████████████████| 1/1 [00:01<00:00,  1.77s/it]\r\n",
      "Batches: 100%|██████████████████████████████████| 81/81 [01:07<00:00,  1.20it/s]\r\n"
     ]
    }
   ],
   "source": [
    "!python run_similarity_search.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eeae27d",
   "metadata": {
    "papermill": {
     "duration": 0.014151,
     "end_time": "2024-11-29T08:28:27.725653",
     "exception": false,
     "start_time": "2024-11-29T08:28:27.711502",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Sanity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75273c00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T08:28:27.754635Z",
     "iopub.status.busy": "2024-11-29T08:28:27.754294Z",
     "iopub.status.idle": "2024-11-29T08:28:27.769818Z",
     "shell.execute_reply": "2024-11-29T08:28:27.768949Z"
    },
    "papermill": {
     "duration": 0.032852,
     "end_time": "2024-11-29T08:28:27.772240",
     "exception": false,
     "start_time": "2024-11-29T08:28:27.739388",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QuestionId_Answer</th>\n",
       "      <th>MisconceptionId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1869_B</td>\n",
       "      <td>2306 1672 2532 2488 15 706 987 328 1999 2175 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1869_C</td>\n",
       "      <td>2306 1672 15 2488 706 2532 1999 328 987 1119 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1869_D</td>\n",
       "      <td>1672 2488 706 2306 2532 15 328 1999 1516 2181 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1870_A</td>\n",
       "      <td>1540 143 2398 353 1610 2078 1593 2307 1825 125...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1870_B</td>\n",
       "      <td>143 1540 2398 1593 2078 891 1825 1610 353 2307...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1870_C</td>\n",
       "      <td>143 2398 1825 1540 353 891 2078 1593 2307 1610...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1871_A</td>\n",
       "      <td>1287 1073 1677 2319 397 1923 1349 691 2551 117...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1871_C</td>\n",
       "      <td>1287 397 1677 1073 2319 1349 2551 691 449 1177...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1871_D</td>\n",
       "      <td>1287 1073 1677 397 2319 1923 1349 2551 691 23 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  QuestionId_Answer                                    MisconceptionId\n",
       "0            1869_B  2306 1672 2532 2488 15 706 987 328 1999 2175 1...\n",
       "1            1869_C  2306 1672 15 2488 706 2532 1999 328 987 1119 2...\n",
       "2            1869_D  1672 2488 706 2306 2532 15 328 1999 1516 2181 ...\n",
       "3            1870_A  1540 143 2398 353 1610 2078 1593 2307 1825 125...\n",
       "4            1870_B  143 1540 2398 1593 2078 891 1825 1610 353 2307...\n",
       "5            1870_C  143 2398 1825 1540 353 891 2078 1593 2307 1610...\n",
       "6            1871_A  1287 1073 1677 2319 397 1923 1349 691 2551 117...\n",
       "7            1871_C  1287 397 1677 1073 2319 1349 2551 691 449 1177...\n",
       "8            1871_D  1287 1073 1677 397 2319 1923 1349 2551 691 23 ..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae64350a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T08:28:27.807219Z",
     "iopub.status.busy": "2024-11-29T08:28:27.806497Z",
     "iopub.status.idle": "2024-11-29T08:28:27.813161Z",
     "shell.execute_reply": "2024-11-29T08:28:27.812374Z"
    },
    "papermill": {
     "duration": 0.023089,
     "end_time": "2024-11-29T08:28:27.815452",
     "exception": false,
     "start_time": "2024-11-29T08:28:27.792363",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IS_SUBMISSION\n"
     ]
    }
   ],
   "source": [
    "if not IS_SUBMISSION:\n",
    "    print(\"IS_NOT_SUBMISSION\")\n",
    "    import pandas as pd\n",
    "    from eedi_metrics import mapk\n",
    "    predicted = pd.read_csv(\"submission.csv\")[\"MisconceptionId\"].apply(lambda x: [int(y) for y in x.split()])\n",
    "    label = pd.read_parquet(\"label.parquet\")[\"MisconceptionId\"]\n",
    "    print(\"Validation: \", mapk(label, predicted))\n",
    "else:\n",
    "    print(\"IS_SUBMISSION\")\n",
    "    # 0.30588741666967073\n",
    "    # 0.24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dcd438c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T08:28:27.845025Z",
     "iopub.status.busy": "2024-11-29T08:28:27.844406Z",
     "iopub.status.idle": "2024-11-29T08:28:27.848305Z",
     "shell.execute_reply": "2024-11-29T08:28:27.847564Z"
    },
    "papermill": {
     "duration": 0.019252,
     "end_time": "2024-11-29T08:28:27.849942",
     "exception": false,
     "start_time": "2024-11-29T08:28:27.830690",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# \"zero shot\" : 0.20870566223577447 \n",
    "# df_test"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 9738540,
     "sourceId": 82695,
     "sourceType": "competition"
    },
    {
     "databundleVersionId": 6613163,
     "datasetId": 3775395,
     "sourceId": 6530547,
     "sourceType": "datasetVersion"
    },
    {
     "databundleVersionId": 10315213,
     "datasetId": 4581967,
     "sourceId": 10042054,
     "sourceType": "datasetVersion"
    },
    {
     "databundleVersionId": 8344064,
     "datasetId": 4871830,
     "sourceId": 8218776,
     "sourceType": "datasetVersion"
    },
    {
     "databundleVersionId": 8179074,
     "modelInstanceId": 23286,
     "sourceId": 27644,
     "sourceType": "modelInstanceVersion"
    },
    {
     "databundleVersionId": 9596746,
     "modelInstanceId": 95303,
     "sourceId": 113573,
     "sourceType": "modelInstanceVersion"
    },
    {
     "sourceId": 193175737,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 200567623,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30762,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 443.342145,
   "end_time": "2024-11-29T08:28:28.581740",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-29T08:21:05.239595",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
